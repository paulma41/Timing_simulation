You are an expert Python developer working on `design_optimizer/jeffreys.py` and `test_multi_model_bo.py`. Implement an adaptive Monte Carlo scheme for the Jeffreys utility computation so that the estimator decides on-the-fly how many samples are needed.

Core requirements:
1. Replace the fixed (`K_outer`, `K_inner`) loops by batched sampling. Start with small batches (e.g., 5×5) and keep accumulating samples.
2. After each batch, estimate the mean and standard error for every `U[i][j]`. Stop sampling a row once all entries meet a confidence tolerance (default: 95% CI half-width ≤ 0.5).
3. Expose new CLI flags in `test_multi_model_bo.py`: `--mc-tolerance` (float, default 0.5) and `--mc-max-batches` (int, default 20). Fall back to the old behaviour when `mc_tolerance <= 0`.
4. Ensure the adaptive logic works both in sequential and parallel modes (`--jobs`), reusing the existing cloudpickle-based ProcessPool.
5. Update docstrings/logging so users know when the adaptive stopping criterion triggers, and keep progress bars meaningful (show remaining rows/batches).

Deliverables: modified `design_optimizer/jeffreys.py`, `test_multi_model_bo.py`, plus any helpers/tests needed. Keep code well-commented and back-compatible.
